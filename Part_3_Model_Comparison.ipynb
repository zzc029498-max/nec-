{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zzc029498-max/nec-/blob/main/Part_3_Model_Comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# Import necessary libraries\n",
        "# ==============================================================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split # Added this necessary import\n",
        "\n",
        "# Import your custom implemented NeuralNet class\n",
        "try:\n",
        "    from NeuralNet import NeuralNet\n",
        "except ImportError:\n",
        "    print(\"Error: Could not import NeuralNet class. Please ensure NeuralNet.py is in the directory.\")\n",
        "    NeuralNet = None\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. Evaluation metric functions\n",
        "# ==============================================================================\n",
        "\n",
        "def calculate_metrics(y_true, y_pred, inverse_transform=True):\n",
        "    \"\"\"\n",
        "    Calculates and returns MSE, MAE, and MAPE.\n",
        "    Assumes y_true and y_pred are in log space if inverse_transform is True.\n",
        "    \"\"\"\n",
        "    if inverse_transform:\n",
        "        # Inverse transform (exponential function) to get original prices\n",
        "        y_true_orig = np.exp(y_true)\n",
        "        y_pred_orig = np.exp(y_pred)\n",
        "    else:\n",
        "        y_true_orig = y_true\n",
        "        y_pred_orig = y_pred\n",
        "\n",
        "    # Mean Squared Error (MSE)\n",
        "    mse = mean_squared_error(y_true_orig, y_pred_orig)\n",
        "\n",
        "    # Mean Absolute Error (MAE)\n",
        "    mae = mean_absolute_error(y_true_orig, y_pred_orig)\n",
        "\n",
        "    # Mean Absolute Percentage Error (MAPE)\n",
        "    # Avoid division by zero and calculate percentage\n",
        "    mape = np.mean(np.abs((y_true_orig - y_pred_orig) / y_true_orig)) * 100\n",
        "\n",
        "    return mse, mae, mape\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. Data loading\n",
        "# ==============================================================================\n",
        "\n",
        "try:\n",
        "    data = np.load('preprocessed_data.npz')\n",
        "\n",
        "    # Extract data from the .npz file\n",
        "    X_train_val = data['X_train_val']\n",
        "    y_train_val = data['y_train_val']\n",
        "    X_test = data['X_test']\n",
        "    y_test = data['y_test']\n",
        "\n",
        "    # Determine number of input features\n",
        "    n_features = X_train_val.shape[1]\n",
        "\n",
        "    print(f\"Data loaded successfully. Number of input features: {n_features}\")\n",
        "    print(f\"Train/Validation set size: {X_train_val.shape[0]}, Test set size: {X_test.shape[0]}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: preprocessed_data.npz file not found. Please ensure Part 1 code was executed.\")\n",
        "    # Create dummy data to allow code execution\n",
        "    n_features = 12\n",
        "    X_train_val = np.random.rand(1000, n_features)\n",
        "    y_train_val = np.random.rand(1000)\n",
        "    X_test = np.random.rand(200, n_features)\n",
        "    y_test = np.random.rand(200)\n",
        "\n",
        "# ==============================================================================\n",
        "# Part 3.1: BP Hyperparameter comparison and selection (at least 10 combinations)\n",
        "# ==============================================================================\n",
        "\n",
        "if NeuralNet is not None:\n",
        "\n",
        "    # --- Define hyperparameter search space ---\n",
        "    # Network architecture (n_features: H1: H2: 1)\n",
        "    architectures = [\n",
        "        [n_features, 10, 5, 1],\n",
        "        [n_features, 20, 1],\n",
        "        [n_features, 50, 20, 1],\n",
        "        [n_features, 10, 1],\n",
        "        [n_features, 30, 15, 1],\n",
        "    ]\n",
        "    # Learning Rate (η)\n",
        "    learning_rates = [0.01, 0.1]\n",
        "    # Momentum (α)\n",
        "    momenta = [0.0, 0.9]\n",
        "    # Activation Function\n",
        "    activation_funcs = ['relu', 'tanh']\n",
        "\n",
        "    # Fixed parameters\n",
        "    N_EPOCHS = 500\n",
        "    VALIDATION_SPLIT = 0.2\n",
        "\n",
        "    # Generate all combinations\n",
        "    hyperparam_combinations = []\n",
        "    for arch in architectures:\n",
        "        for lr in learning_rates:\n",
        "            for momentum in momenta:\n",
        "                for func in activation_funcs:\n",
        "                    # Filter out some combinations for stability\n",
        "                    if func == 'relu' and lr > 0.05:\n",
        "                        continue\n",
        "\n",
        "                    if func == 'tanh' and momentum == 0.0:\n",
        "                        continue\n",
        "\n",
        "                    hyperparam_combinations.append({\n",
        "                        'arch': arch[1:], # Pass only hidden and output layers\n",
        "                        'lr': lr,\n",
        "                        'momentum': momentum,\n",
        "                        'func': func\n",
        "                    })\n",
        "\n",
        "    # Ensure at least 10 combinations\n",
        "    if len(hyperparam_combinations) < 10:\n",
        "        hyperparam_combinations = hyperparam_combinations * (10 // len(hyperparam_combinations) + 1)\n",
        "        hyperparam_combinations = hyperparam_combinations[:10]\n",
        "\n",
        "\n",
        "    # --- Search Loop ---\n",
        "    bp_results = []\n",
        "\n",
        "    print(f\"\\n--- 3.1 BP Neural Network Hyperparameter Search (Total {len(hyperparam_combinations)} combinations) ---\")\n",
        "\n",
        "    for i, params in enumerate(hyperparam_combinations):\n",
        "\n",
        "        # Full network architecture: [Input layer size] + [Hidden/Output layer sizes]\n",
        "        full_arch = [n_features] + params['arch']\n",
        "\n",
        "        # 1. Train BP Model\n",
        "        nn = NeuralNet(\n",
        "            network_architecture=full_arch,\n",
        "            n_epochs=N_EPOCHS,\n",
        "            learning_rate=params['lr'],\n",
        "            momentum=params['momentum'],\n",
        "            activation_function=params['func'],\n",
        "            validation_split=VALIDATION_SPLIT\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            # Training (fit method splits X_train_val into train/validation sets internally)\n",
        "            print(f\"\\n[{i+1}/{len(hyperparam_combinations)}] Training Arch: {params['arch']}, LR: {params['lr']}, Mom: {params['momentum']}, Func: {params['func']}\")\n",
        "            nn.fit(X_train_val, y_train_val)\n",
        "\n",
        "            # 2. Predict validation set (Evaluate hyperparameters)\n",
        "            # Re-split data to ensure correct validation set for prediction check\n",
        "            _, X_val, _, y_val = train_test_split(\n",
        "                X_train_val, y_train_val, test_size=VALIDATION_SPLIT, shuffle=True\n",
        "            )\n",
        "\n",
        "            y_val_pred_log = nn.predict(X_val).ravel()\n",
        "\n",
        "            # 3. Calculate metrics\n",
        "            mse, mae, mape = calculate_metrics(y_val, y_val_pred_log)\n",
        "\n",
        "            # 4. Store results and loss history\n",
        "            bp_results.append({\n",
        "                \"Layers\": nn.L,\n",
        "                \"Architecture\": str(params['arch']),\n",
        "                \"Epochs\": N_EPOCHS,\n",
        "                \"LearningRate\": params['lr'],\n",
        "                \"Momentum\": params['momentum'],\n",
        "                \"Activation\": params['func'],\n",
        "                \"MAPE\": mape,\n",
        "                \"MAE\": mae,\n",
        "                \"MSE\": mse,\n",
        "                \"loss_history\": nn.loss_epochs(),\n",
        "                \"val_predictions\": np.exp(y_val_pred_log),\n",
        "                \"val_true\": np.exp(y_val)\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Training combination {i+1} failed: {e}\")\n",
        "            bp_results.append({\n",
        "                \"Layers\": nn.L,\n",
        "                \"Architecture\": str(params['arch']),\n",
        "                \"Epochs\": N_EPOCHS,\n",
        "                \"LearningRate\": params['lr'],\n",
        "                \"Momentum\": params['momentum'],\n",
        "                \"Activation\": params['func'],\n",
        "                \"MAPE\": np.nan, \"MAE\": np.nan, \"MSE\": np.nan,\n",
        "                \"loss_history\": np.zeros((N_EPOCHS, 2)) * np.nan\n",
        "            })\n",
        "\n",
        "    # --- Results Summary and Best Model Selection ---\n",
        "    bp_df = pd.DataFrame(bp_results).sort_values(by='MAPE', ascending=True).reset_index(drop=True)\n",
        "\n",
        "    # Report requirement: Table summary of hyperparameter quality\n",
        "    print(\"\\n\\n--- Report Requirement 3.1: BP Neural Network Hyperparameter Search Results (Sorted by MAPE) ---\")\n",
        "    print(bp_df[['Layers', 'Architecture', 'Epochs', 'LearningRate', 'Momentum', 'Activation', 'MAPE', 'MAE', 'MSE']].head(10).to_markdown(index=False, floatfmt=\".4f\"))\n",
        "\n",
        "    # Select the best model (lowest MAPE)\n",
        "    best_bp_params = bp_df.iloc[0]\n",
        "    print(f\"\\nBest BP Model Parameters (MAPE: {best_bp_params['MAPE']:.4f}) selected.\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# Part 3.2: Model comparison (BP, MLR-F, BP-F)\n",
        "# ==============================================================================\n",
        "\n",
        "# --- 1. Retrain/Evaluate Best BP Model (using all train/validation data) ---\n",
        "if NeuralNet is not None:\n",
        "    print(\"\\n--- 3.2 Training Best BP Model and evaluating Test Set ---\")\n",
        "\n",
        "    # Best BP model's full architecture\n",
        "    best_arch = [n_features] + best_bp_params['arch']\n",
        "\n",
        "    # Re-instantiate and train the best BP model (using 0.0 validation_split to use all X_train_val)\n",
        "    best_bp_model = NeuralNet(\n",
        "        network_architecture=best_arch,\n",
        "        n_epochs=N_EPOCHS,\n",
        "        learning_rate=best_bp_params['lr'],\n",
        "        momentum=best_bp_params['momentum'],\n",
        "        activation_function=best_bp_params['func'],\n",
        "        validation_split=0.0 # Use all X_train_val for training\n",
        "    )\n",
        "\n",
        "    # Actual training\n",
        "    try:\n",
        "        best_bp_model.fit(X_train_val, y_train_val)\n",
        "        y_test_pred_bp_log = best_bp_model.predict(X_test).ravel()\n",
        "\n",
        "        # Calculate test set metrics\n",
        "        metrics_bp = calculate_metrics(y_test, y_test_pred_bp_log)\n",
        "        y_test_pred_bp_orig = np.exp(y_test_pred_bp_log)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Retraining best BP model failed: {e}\")\n",
        "        metrics_bp = (np.nan, np.nan, np.nan)\n",
        "        y_test_pred_bp_orig = np.zeros_like(y_test) * np.nan\n",
        "\n",
        "\n",
        "else:\n",
        "    metrics_bp = (np.nan, np.nan, np.nan)\n",
        "    y_test_pred_bp_orig = np.zeros_like(y_test) * np.nan\n",
        "\n",
        "\n",
        "# --- 2. Train MLR-F (Multiple Linear Regression - Scikit-learn) ---\n",
        "print(\"\\n--- Training MLR-F Model and evaluating Test Set ---\")\n",
        "\n",
        "# Instantiate and train model\n",
        "mlr_model = LinearRegression()\n",
        "mlr_model.fit(X_train_val, y_train_val)\n",
        "\n",
        "# Predict test set\n",
        "y_test_pred_mlr_log = mlr_model.predict(X_test)\n",
        "\n",
        "# Calculate test set metrics\n",
        "metrics_mlr = calculate_metrics(y_test, y_test_pred_mlr_log)\n",
        "y_test_pred_mlr_orig = np.exp(y_test_pred_mlr_log)\n",
        "\n",
        "\n",
        "# --- 3. Train BP-F (Framework Neural Network - Scikit-learn MLP) ---\n",
        "print(\"\\n--- Training BP-F Model and evaluating Test Set ---\")\n",
        "\n",
        "# BP-F Parameters\n",
        "bp_f_params = {\n",
        "    'hidden_layer_sizes': (30, 15),\n",
        "    'activation': 'relu',\n",
        "    'solver': 'adam',\n",
        "    'max_iter': N_EPOCHS,\n",
        "    'random_state': 42,\n",
        "    'alpha': 0.001, # L2 regularization term\n",
        "    'learning_rate_init': 0.001,\n",
        "}\n",
        "print(f\"BP-F Model Description: hidden_layer_sizes={bp_f_params['hidden_layer_sizes']}, activation={bp_f_params['activation']}, max_iter={bp_f_params['max_iter']}\")\n",
        "\n",
        "# Instantiate and train model\n",
        "bp_f_model = MLPRegressor(**bp_f_params)\n",
        "# MLPRegressor standardizes data by default, but ours is already preprocessed.\n",
        "bp_f_model.fit(X_train_val, y_train_val)\n",
        "\n",
        "# Predict test set\n",
        "y_test_pred_bpf_log = bp_f_model.predict(X_test)\n",
        "\n",
        "# Calculate test set metrics\n",
        "metrics_bpf = calculate_metrics(y_test, y_test_pred_bpf_log)\n",
        "y_test_pred_bpf_orig = np.exp(y_test_pred_bpf_log)\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. Final Comparison Table (Report Requirement 3.2)\n",
        "# ==============================================================================\n",
        "\n",
        "results_comparison = pd.DataFrame({\n",
        "    \"Model\": [\"BP (Student Impl.)\", \"MLR-F (Linear Regression)\", \"BP-F (MLP Regressor)\"],\n",
        "    \"Parameter Description\": [\n",
        "        f\"Arch: {best_bp_params['arch']}, LR: {best_bp_params['lr']}, Mom: {best_bp_params['momentum']}, Func: {best_bp_params['func']}\",\n",
        "        \"Scikit-learn Default\",\n",
        "        f\"Arch: {bp_f_params['hidden_layer_sizes']}, L2: {bp_f_params['alpha']}\"\n",
        "    ],\n",
        "    \"MSE\": [metrics_bp[0], metrics_mlr[0], metrics_bpf[0]],\n",
        "    \"MAE\": [metrics_bp[1], metrics_mlr[1], metrics_bpf[1]],\n",
        "    \"MAPE\": [metrics_bp[2], metrics_mlr[2], metrics_bpf[2]],\n",
        "})\n",
        "\n",
        "print(\"\\n\\n--- Report Requirement 3.2: Prediction Quality Comparison on Test Set ---\")\n",
        "print(results_comparison.to_markdown(index=False, floatfmt=\".2f\"))\n",
        "\n",
        "# ==============================================================================\n",
        "# 5. Generate Plotting Data (Report Requirements 3.1 & 3.2)\n",
        "# ==============================================================================\n",
        "\n",
        "# --- 5.1 Loss Evolution Plot Data (Report Requirement 3.1) ---\n",
        "if NeuralNet is not None and len(bp_df) > 0:\n",
        "    print(\"\\n--- Generating BP Loss Evolution Plot Data ---\")\n",
        "\n",
        "    # Example: Select loss history for Best, Second Best, and Worst models\n",
        "    plot_models = [\n",
        "        (\"Best BP Model\", bp_df.iloc[0]),\n",
        "        (\"Second Best BP Model\", bp_df.iloc[1]),\n",
        "        (\"Worst BP Model\", bp_df.iloc[-1])\n",
        "    ]\n",
        "\n",
        "    # Structure to store data for plotting\n",
        "    bp_loss_plots_data = []\n",
        "    for name, row in plot_models:\n",
        "        bp_loss_plots_data.append({\n",
        "            \"name\": f\"{name} ({row['Architecture']}-{row['Activation']})\",\n",
        "            \"loss_history\": row['loss_history']\n",
        "        })\n",
        "\n",
        "    # (Use matplotlib to plot this data in your report)\n",
        "\n",
        "\n",
        "# --- 5.2 Predicted vs True Value Scatter Plot Data (Report Requirements 3.1 & 3.2) ---\n",
        "print(\"\\n--- Generating Predicted vs True Value Scatter Plot Data ---\")\n",
        "\n",
        "# True values (Inverse transformed)\n",
        "y_test_orig = np.exp(y_test)\n",
        "\n",
        "# Data structure for comparison plots\n",
        "comparison_scatter_data = [\n",
        "    {\n",
        "        \"model\": \"BP (Student Impl.) - Best\",\n",
        "        \"y_true\": y_test_orig,\n",
        "        \"y_pred\": y_test_pred_bp_orig,\n",
        "    },\n",
        "    {\n",
        "        \"model\": \"MLR-F (Linear Regression)\",\n",
        "        \"y_true\": y_test_orig,\n",
        "        \"y_pred\": y_test_pred_mlr_orig,\n",
        "    },\n",
        "    {\n",
        "        \"model\": \"BP-F (MLP Regressor)\",\n",
        "        \"y_true\": y_test_orig,\n",
        "        \"y_pred\": y_test_pred_bpf_orig,\n",
        "    },\n",
        "]\n",
        "\n",
        "# (Use matplotlib to plot this data in your report)\n",
        "\n",
        "# You also need scatter data for 2-3 representative models from the validation set (stored in bp_df)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "OeRIeXLWTqtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFUTSBewTzKs",
        "outputId": "edd6078c-ebc8-47d4-d0fc-73aa97de32e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}